{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Fast Laplacian Eigenmaps in python Open-source Laplacian Eigenmaps algorithm for dimensionality reduction of large data in python. Comes with an wrapper for NMSlib to compute approximate-nearest-neighbors. Performs several times faster than the default scikit-learn implementation . fastlapmap was developed by Davi Sidarta-Oliveira . Installation You'll need NMSlib for using this package properly. Installing it with no binaries is recommended if your CPU supports advanced instructions (it problably does): pip3 install --no-binary :all: nmslib # Along with requirements: pip3 install numpy pandas scipy scikit-learn Then you can install this package with pip: pip3 install fastlapmap","title":"Welcome!"},{"location":"#fast-laplacian-eigenmaps-in-python","text":"Open-source Laplacian Eigenmaps algorithm for dimensionality reduction of large data in python. Comes with an wrapper for NMSlib to compute approximate-nearest-neighbors. Performs several times faster than the default scikit-learn implementation . fastlapmap was developed by Davi Sidarta-Oliveira .","title":"Fast Laplacian Eigenmaps in python"},{"location":"#installation","text":"You'll need NMSlib for using this package properly. Installing it with no binaries is recommended if your CPU supports advanced instructions (it problably does): pip3 install --no-binary :all: nmslib # Along with requirements: pip3 install numpy pandas scipy scikit-learn Then you can install this package with pip: pip3 install fastlapmap","title":"Installation"},{"location":"ann/","text":"fastlapmap.ann.NMSlibTransformer Wrapper for using nmslib as sklearn's KNeighborsTransformer. This implements an escalable approximate k-nearest-neighbors graph on spaces defined by nmslib. Read more about nmslib and its various available metrics at the original repository Calling nbrs = NMSlibTransformer() initializes the class with default neighbour search parameters. Parameters n_neighbors : int (optional, default 30) number of nearest-neighbors to look for. In practice, this should be considered the average neighborhood size and thus vary depending on your number of features, samples and data intrinsic dimensionality. Reasonable values range from 5 to 100. Smaller values tend to lead to increased graph structure resolution, but users should beware that a too low value may render granulated and vaguely defined neighborhoods that arise as an artifact of downsampling. Defaults to 30. Larger values can slightly increase computational time. metric : str (optional, default 'cosine'). Accepted NMSLIB metrics. Defaults to 'cosine'. Accepted metrics include: -'sqeuclidean' -'euclidean' -'l1' -'lp' - requires setting the parameter p - equivalent to minkowski distance -'cosine' -'angular' -'negdotprod' -'levenshtein' -'hamming' -'jaccard' -'jansen-shan' method : str (optional, default 'hsnw'). approximate-neighbor search method. Available methods include: -'hnsw' : a Hierarchical Navigable Small World Graph. -'sw-graph' : a Small World Graph. -'vp-tree' : a Vantage-Point tree with a pruning rule adaptable to non-metric distances. -'napp' : a Neighborhood APProximation index. -'simple_invindx' : a vanilla, uncompressed, inverted index, which has no parameters. -'brute_force' : a brute-force search, which has no parameters. 'hnsw' is usually the fastest method, followed by 'sw-graph' and 'vp-tree'. n_jobs : int (optional, default 1). number of threads to be used in computation. Defaults to 1. The algorithm is highly scalable to multi-threading. M : int (optional, default 10). defines the maximum number of neighbors in the zero and above-zero layers during HSNW (Hierarchical Navigable Small World Graph). However, the actual default maximum number of neighbors for the zero layer is 2*M. A reasonable range for this parameter is 5-100. For more information on HSNW, please check https://arxiv.org/abs/1603.09320. HSNW is implemented in python via NMSlib. Please check more about NMSlib at https://github.com/nmslib/nmslib. efC : int (optional, default 20). A 'hnsw' parameter. Increasing this value improves the quality of a constructed graph and leads to higher accuracy of search. However this also leads to longer indexing times. A reasonable range for this parameter is 10-500. efS : int (optional, default 100). A 'hnsw' parameter. Similarly to efC, increasing this value improves recall at the expense of longer retrieval time. A reasonable range for this parameter is 10-500. dense : bool (optional, default False). Whether to force the algorithm to use dense data, such as np.ndarrays and pandas DataFrames. Returns Class for really fast approximate-nearest-neighbors search. Example import numpy as np from sklearn.datasets import load_digits from scipy.sparse import csr_matrix from topo.base.ann import NMSlibTransformer # # Load the MNIST digits data, convert to sparse for speed digits = load_digits() data = csr_matrix(digits) # # Start class with parameters nn = NMSlibTransformer() nn = nn.fit(data) # # Obtain kNN graph knn = nn.transform(data) # # Obtain kNN indices, distances and distance gradient ind, dist, grad = nn.ind_dist_grad(data) # # Test for recall efficiency during approximate nearest neighbors search test = nn.test_efficiency(data) fit_transform ( self , X ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X. Parameters X : {array-like, sparse matrix, dataframe} of shape (n_samples, n_features) y : ndarray of shape (n_samples,), default=None Target values. **fit_params : dict Additional fit parameters. Returns X_new : ndarray array of shape (n_samples, n_features_new) Transformed array. Source code in fastlapmap/ann.py def fit_transform ( self , X ): self . fit ( X ) return self . transform ( X ) test_efficiency ( self , data , data_use = 0.1 ) Test if NMSlibTransformer and KNeighborsTransformer give same results Source code in fastlapmap/ann.py def test_efficiency ( self , data , data_use = 0.1 ): \"\"\"Test if NMSlibTransformer and KNeighborsTransformer give same results \"\"\" self . data_use = data_use query_qty = data . shape [ 0 ] ( dismiss , test ) = train_test_split ( data , test_size = self . data_use ) query_time_params = { 'efSearch' : self . efS } if self . verbose : print ( 'Setting query-time parameters' , query_time_params ) self . nmslib_ . setQueryTimeParams ( query_time_params ) # For compatibility reasons, as each sample is considered as its own # neighbor, one extra neighbor will be computed. self . n_neighbors = self . n_neighbors + 1 start = time . time () ann_results = self . nmslib_ . knnQueryBatch ( data , k = self . n_neighbors , num_threads = self . n_jobs ) end = time . time () if self . verbose : print ( 'kNN time total= %f (sec), per query= %f (sec), per query adjusted for thread number= %f (sec)' % ( end - start , float ( end - start ) / query_qty , self . n_jobs * float ( end - start ) / query_qty )) # Use sklearn for exact neighbor search start = time . time () nbrs = NearestNeighbors ( n_neighbors = self . n_neighbors , metric = self . metric , algorithm = 'brute' ) . fit ( data ) knn = nbrs . kneighbors ( data ) end = time . time () if self . verbose : print ( 'brute-force gold-standart kNN time total= %f (sec), per query= %f (sec)' % ( end - start , float ( end - start ) / query_qty )) recall = 0.0 for i in range ( 0 , query_qty ): correct_set = set ( knn [ 1 ][ i ]) ret_set = set ( ann_results [ i ][ 0 ]) recall = recall + float ( len ( correct_set . intersection ( ret_set ))) / len ( correct_set ) recall = recall / query_qty print ( 'kNN recall %f ' % recall ) update_search ( self , n_neighbors ) Updates number of neighbors for kNN distance computation. Parameters n_neighbors: New number of neighbors to look for. Source code in fastlapmap/ann.py def update_search ( self , n_neighbors ): \"\"\" Updates number of neighbors for kNN distance computation. Parameters ----------- n_neighbors: New number of neighbors to look for. \"\"\" self . n_neighbors = n_neighbors return print ( 'Updated neighbor search.' )","title":"Approximate nearest-neighbors"},{"location":"ann/#fastlapmap.ann.NMSlibTransformer","text":"Wrapper for using nmslib as sklearn's KNeighborsTransformer. This implements an escalable approximate k-nearest-neighbors graph on spaces defined by nmslib. Read more about nmslib and its various available metrics at the original repository Calling nbrs = NMSlibTransformer() initializes the class with default neighbour search parameters.","title":"NMSlibTransformer"},{"location":"ann/#fastlapmap.ann.NMSlibTransformer--parameters","text":"n_neighbors : int (optional, default 30) number of nearest-neighbors to look for. In practice, this should be considered the average neighborhood size and thus vary depending on your number of features, samples and data intrinsic dimensionality. Reasonable values range from 5 to 100. Smaller values tend to lead to increased graph structure resolution, but users should beware that a too low value may render granulated and vaguely defined neighborhoods that arise as an artifact of downsampling. Defaults to 30. Larger values can slightly increase computational time. metric : str (optional, default 'cosine'). Accepted NMSLIB metrics. Defaults to 'cosine'. Accepted metrics include: -'sqeuclidean' -'euclidean' -'l1' -'lp' - requires setting the parameter p - equivalent to minkowski distance -'cosine' -'angular' -'negdotprod' -'levenshtein' -'hamming' -'jaccard' -'jansen-shan' method : str (optional, default 'hsnw'). approximate-neighbor search method. Available methods include: -'hnsw' : a Hierarchical Navigable Small World Graph. -'sw-graph' : a Small World Graph. -'vp-tree' : a Vantage-Point tree with a pruning rule adaptable to non-metric distances. -'napp' : a Neighborhood APProximation index. -'simple_invindx' : a vanilla, uncompressed, inverted index, which has no parameters. -'brute_force' : a brute-force search, which has no parameters. 'hnsw' is usually the fastest method, followed by 'sw-graph' and 'vp-tree'. n_jobs : int (optional, default 1). number of threads to be used in computation. Defaults to 1. The algorithm is highly scalable to multi-threading. M : int (optional, default 10). defines the maximum number of neighbors in the zero and above-zero layers during HSNW (Hierarchical Navigable Small World Graph). However, the actual default maximum number of neighbors for the zero layer is 2*M. A reasonable range for this parameter is 5-100. For more information on HSNW, please check https://arxiv.org/abs/1603.09320. HSNW is implemented in python via NMSlib. Please check more about NMSlib at https://github.com/nmslib/nmslib. efC : int (optional, default 20). A 'hnsw' parameter. Increasing this value improves the quality of a constructed graph and leads to higher accuracy of search. However this also leads to longer indexing times. A reasonable range for this parameter is 10-500. efS : int (optional, default 100). A 'hnsw' parameter. Similarly to efC, increasing this value improves recall at the expense of longer retrieval time. A reasonable range for this parameter is 10-500. dense : bool (optional, default False). Whether to force the algorithm to use dense data, such as np.ndarrays and pandas DataFrames.","title":"Parameters"},{"location":"ann/#fastlapmap.ann.NMSlibTransformer--returns","text":"Class for really fast approximate-nearest-neighbors search.","title":"Returns"},{"location":"ann/#fastlapmap.ann.NMSlibTransformer--example","text":"import numpy as np from sklearn.datasets import load_digits from scipy.sparse import csr_matrix from topo.base.ann import NMSlibTransformer # # Load the MNIST digits data, convert to sparse for speed digits = load_digits() data = csr_matrix(digits) # # Start class with parameters nn = NMSlibTransformer() nn = nn.fit(data) # # Obtain kNN graph knn = nn.transform(data) # # Obtain kNN indices, distances and distance gradient ind, dist, grad = nn.ind_dist_grad(data) # # Test for recall efficiency during approximate nearest neighbors search test = nn.test_efficiency(data)","title":"Example"},{"location":"ann/#fastlapmap.ann.NMSlibTransformer.fit_transform","text":"Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.","title":"fit_transform()"},{"location":"ann/#fastlapmap.ann.NMSlibTransformer.fit_transform--parameters","text":"X : {array-like, sparse matrix, dataframe} of shape (n_samples, n_features) y : ndarray of shape (n_samples,), default=None Target values. **fit_params : dict Additional fit parameters.","title":"Parameters"},{"location":"ann/#fastlapmap.ann.NMSlibTransformer.fit_transform--returns","text":"X_new : ndarray array of shape (n_samples, n_features_new) Transformed array. Source code in fastlapmap/ann.py def fit_transform ( self , X ): self . fit ( X ) return self . transform ( X )","title":"Returns"},{"location":"ann/#fastlapmap.ann.NMSlibTransformer.test_efficiency","text":"Test if NMSlibTransformer and KNeighborsTransformer give same results Source code in fastlapmap/ann.py def test_efficiency ( self , data , data_use = 0.1 ): \"\"\"Test if NMSlibTransformer and KNeighborsTransformer give same results \"\"\" self . data_use = data_use query_qty = data . shape [ 0 ] ( dismiss , test ) = train_test_split ( data , test_size = self . data_use ) query_time_params = { 'efSearch' : self . efS } if self . verbose : print ( 'Setting query-time parameters' , query_time_params ) self . nmslib_ . setQueryTimeParams ( query_time_params ) # For compatibility reasons, as each sample is considered as its own # neighbor, one extra neighbor will be computed. self . n_neighbors = self . n_neighbors + 1 start = time . time () ann_results = self . nmslib_ . knnQueryBatch ( data , k = self . n_neighbors , num_threads = self . n_jobs ) end = time . time () if self . verbose : print ( 'kNN time total= %f (sec), per query= %f (sec), per query adjusted for thread number= %f (sec)' % ( end - start , float ( end - start ) / query_qty , self . n_jobs * float ( end - start ) / query_qty )) # Use sklearn for exact neighbor search start = time . time () nbrs = NearestNeighbors ( n_neighbors = self . n_neighbors , metric = self . metric , algorithm = 'brute' ) . fit ( data ) knn = nbrs . kneighbors ( data ) end = time . time () if self . verbose : print ( 'brute-force gold-standart kNN time total= %f (sec), per query= %f (sec)' % ( end - start , float ( end - start ) / query_qty )) recall = 0.0 for i in range ( 0 , query_qty ): correct_set = set ( knn [ 1 ][ i ]) ret_set = set ( ann_results [ i ][ 0 ]) recall = recall + float ( len ( correct_set . intersection ( ret_set ))) / len ( correct_set ) recall = recall / query_qty print ( 'kNN recall %f ' % recall )","title":"test_efficiency()"},{"location":"ann/#fastlapmap.ann.NMSlibTransformer.update_search","text":"Updates number of neighbors for kNN distance computation. Parameters n_neighbors: New number of neighbors to look for. Source code in fastlapmap/ann.py def update_search ( self , n_neighbors ): \"\"\" Updates number of neighbors for kNN distance computation. Parameters ----------- n_neighbors: New number of neighbors to look for. \"\"\" self . n_neighbors = n_neighbors return print ( 'Updated neighbor search.' )","title":"update_search()"},{"location":"benchmark/","text":"Benchmark See the runtime comparison between this implementation and scikit-learn: ## Load benchmark function: from fastlapmap.benchmark import runtime_benchmark # Load data from sklearn.datasets import load_digits digits = load_digits() data = digits.data # Define hyperparameters N_EIGS = 2 N_NEIGHBORS = 10 N_JOBS = 10 SIZES = [1000, 5000, 10000, 25000, 50000, 100000] N_RUNS = 3 runtime_benchmark(data, n_eigs=N_EIGS, n_neighbors=N_NEIGHBORS, n_jobs=N_JOBS, sizes=SIZES, n_runs=N_RUNS) As you can see, the diffusion harmoics model is the fastest, followed closely by fuzzy simplicial sets. Both outperform scikit-learn default implementation and escalate linearly with sample size.","title":"Benchmark"},{"location":"benchmark/#benchmark","text":"See the runtime comparison between this implementation and scikit-learn: ## Load benchmark function: from fastlapmap.benchmark import runtime_benchmark # Load data from sklearn.datasets import load_digits digits = load_digits() data = digits.data # Define hyperparameters N_EIGS = 2 N_NEIGHBORS = 10 N_JOBS = 10 SIZES = [1000, 5000, 10000, 25000, 50000, 100000] N_RUNS = 3 runtime_benchmark(data, n_eigs=N_EIGS, n_neighbors=N_NEIGHBORS, n_jobs=N_JOBS, sizes=SIZES, n_runs=N_RUNS) As you can see, the diffusion harmoics model is the fastest, followed closely by fuzzy simplicial sets. Both outperform scikit-learn default implementation and escalate linearly with sample size.","title":"Benchmark"},{"location":"cknn/","text":"fastlapmap . similarities . cknn_graph ( X , n_neighbors = 10 , delta = 1.0 , metric = 'euclidean' , n_jobs = 1 , efC = 20 , efS = 20 , M = 10 , p = 0.6875 , t = 'inf' , include_self = True , is_sparse = False , return_adj = True , verbose = False ) Continuous k-nearest-neighbors. CkNN is the unique unweighted construction that yields a geometry consistent with the connected components of the underlying manifold in the limit of large data. See the CkNN manuscript for details. Parameters X : input data. May be a numpy.ndarray, a pandas.DataFrame or a scipy.sparse.csr_matrix.numpy n_neighbors : int (optional, default 5) Number of neighbors to estimate the density around the point. It appeared as a parameter k in the paper. delta : float (optional, default 1.0) A parameter to decide the radius for each points. The combination radius increases in proportion to this parameter . metric : str (optional, default 'euclidean'). which metric to use when computing neighborhood distances. Defaults to 'euclidean'. Accepted metrics include: -'sqeuclidean' -'euclidean' -'l1' -'lp' - requires setting the parameter p - equivalent to minkowski distance -'cosine' -'angular' -'negdotprod' -'levenshtein' -'hamming' -'jaccard' -'jansen-shan' n_jobs : int (optional, default 1). number of threads to be used in computation. Defaults to 1. The algorithm is highly scalable to multi-threading. M : int (optional, default 10). defines the maximum number of neighbors in the zero and above-zero layers during HSNW (Hierarchical Navigable Small World Graph). However, the actual default maximum number of neighbors for the zero layer is 2*M. A reasonable range for this parameter is 5-100. For more information on HSNW, please check https://arxiv.org/abs/1603.09320. HSNW is implemented in python via NMSlib. Please check more about NMSlib at https://github.com/nmslib/nmslib. efC : int (optional, default 20). A 'hnsw' parameter. Increasing this value improves the quality of a constructed graph and leads to higher accuracy of search. However this also leads to longer indexing times. A reasonable range for this parameter is 10-500. efS : int (optional, default 100). A 'hnsw' parameter. Similarly to efC, increasing this value improves recall at the expense of longer retrieval time. A reasonable range for this parameter is 10-500. t : 'inf' or float or int (optional, default='inf') The decay parameter of heat kernel. The weights are calculated as !!! follow W_{ij} = exp(-(||x_{i}-x_{j}||^2)/t) For more infomation, read the paper 'Laplacian Eigenmaps for Dimensionality Reduction and Data Representation', Belkin, et. al. include_self : bool (optional, default True). All diagonal elements are 1.0 if this parameter is True. is_sparse : bool (optional, default True). Returns a scipy.sparse.csr_matrix object if this parameter is True. Otherwise, returns numpy.ndarray object. return_adj : bool (optional, default False) Whether to return the adjacency matrix instead. verbose : bool (optional, default False). Whether to report information on the current progress of the algorithm. Returns The affinity (or adjacency) matrix as a scipy.sparse.csr_matrix or numpy.ndarray object, depending on is_sparse and on return_adj . Source code in fastlapmap/similarities.py def cknn_graph ( X , n_neighbors = 10 , delta = 1.0 , metric = 'euclidean' , n_jobs = 1 , efC = 20 , efS = 20 , M = 10 , p = 11 / 16 , t = 'inf' , include_self = True , is_sparse = False , return_adj = True , verbose = False ): \"\"\" Continuous k-nearest-neighbors. CkNN is the unique unweighted construction that yields a geometry consistent with the connected components of the underlying manifold in the limit of large data. See the [CkNN manuscript](http://dx.doi.org/10.3934/fods.2019001) for details. ---------- Parameters ---------- `X` : input data. May be a numpy.ndarray, a pandas.DataFrame or a scipy.sparse.csr_matrix.numpy `n_neighbors` : int (optional, default 5) Number of neighbors to estimate the density around the point. It appeared as a parameter `k` in the paper. `delta` : float (optional, default 1.0) A parameter to decide the radius for each points. The combination radius increases in proportion to this parameter . `metric` : str (optional, default 'euclidean'). which metric to use when computing neighborhood distances. Defaults to 'euclidean'. Accepted metrics include: -'sqeuclidean' -'euclidean' -'l1' -'lp' - requires setting the parameter `p` - equivalent to minkowski distance -'cosine' -'angular' -'negdotprod' -'levenshtein' -'hamming' -'jaccard' -'jansen-shan' `n_jobs` : int (optional, default 1). number of threads to be used in computation. Defaults to 1. The algorithm is highly scalable to multi-threading. `M` : int (optional, default 10). defines the maximum number of neighbors in the zero and above-zero layers during HSNW (Hierarchical Navigable Small World Graph). However, the actual default maximum number of neighbors for the zero layer is 2*M. A reasonable range for this parameter is 5-100. For more information on HSNW, please check https://arxiv.org/abs/1603.09320. HSNW is implemented in python via NMSlib. Please check more about NMSlib at https://github.com/nmslib/nmslib. `efC` : int (optional, default 20). A 'hnsw' parameter. Increasing this value improves the quality of a constructed graph and leads to higher accuracy of search. However this also leads to longer indexing times. A reasonable range for this parameter is 10-500. `efS` : int (optional, default 100). A 'hnsw' parameter. Similarly to efC, increasing this value improves recall at the expense of longer retrieval time. A reasonable range for this parameter is 10-500. `t` : 'inf' or float or int (optional, default='inf') The decay parameter of heat kernel. The weights are calculated as follow: W_{ij} = exp(-(||x_{i}-x_{j}||^2)/t) For more infomation, read the paper 'Laplacian Eigenmaps for Dimensionality Reduction and Data Representation', Belkin, et. al. `include_self` : bool (optional, default True). All diagonal elements are 1.0 if this parameter is True. `is_sparse` : bool (optional, default True). Returns a scipy.sparse.csr_matrix object if this parameter is True. Otherwise, returns numpy.ndarray object. `return_adj` : bool (optional, default False) Whether to return the adjacency matrix instead. `verbose` : bool (optional, default False). Whether to report information on the current progress of the algorithm. ---------- Returns ---------- The affinity (or adjacency) matrix as a scipy.sparse.csr_matrix or numpy.ndarray object, depending on `is_sparse` and on `return_adj`. \"\"\" n_samples = X . shape [ 0 ] if n_neighbors < 1 or n_neighbors > n_samples - 1 : raise ValueError ( \"`n_neighbors` must be \" \"in the range 1 to number of samples\" ) if len ( X . shape ) != 2 : raise ValueError ( \"`X` must be 2D matrix\" ) if n_samples < 2 : raise ValueError ( \"At least 2 data points are required\" ) if metric == 'precomputed' : if X . shape [ 0 ] != X . shape [ 1 ]: raise ValueError ( \"`X` must be square matrix\" ) dmatrix = X else : knn = NMSlibTransformer ( n_neighbors = n_neighbors , metric = metric , p = p , n_jobs = n_jobs , M = M , efC = efC , efS = efS , verbose = verbose ) . fit_transform ( X ) dmatrix = knn . toarray () darray_n_nbrs = np . partition ( dmatrix , n_neighbors )[:, [ n_neighbors ]] # prevent approximately null results (div by 0) div_matrix = np . sqrt ( darray_n_nbrs . dot ( darray_n_nbrs . T )) + 1e-12 ratio_matrix = dmatrix / div_matrix diag_ptr = np . arange ( n_samples ) if isinstance ( delta , ( int , float )): ValueError ( \"Invalid argument type. \" \"Type of `delta` must be float or int\" ) A = csr_matrix ( ratio_matrix < delta ) if include_self : A [ diag_ptr , diag_ptr ] = True else : A [ diag_ptr , diag_ptr ] = False if return_adj : return A else : if t == 'inf' : K = A . astype ( np . float ) else : mask = A . nonzero () weights = np . exp ( - np . power ( dmatrix [ mask ], 2 ) / t ) dmatrix [:] = 0. dmatrix [ mask ] = weights K = csr_matrix ( dmatrix ) if not is_sparse : K = K . toarray () return K","title":"Continuous k-nearest-neighbors"},{"location":"cknn/#fastlapmap.similarities.cknn_graph","text":"Continuous k-nearest-neighbors. CkNN is the unique unweighted construction that yields a geometry consistent with the connected components of the underlying manifold in the limit of large data. See the CkNN manuscript for details.","title":"cknn_graph()"},{"location":"cknn/#fastlapmap.similarities.cknn_graph--parameters","text":"X : input data. May be a numpy.ndarray, a pandas.DataFrame or a scipy.sparse.csr_matrix.numpy n_neighbors : int (optional, default 5) Number of neighbors to estimate the density around the point. It appeared as a parameter k in the paper. delta : float (optional, default 1.0) A parameter to decide the radius for each points. The combination radius increases in proportion to this parameter . metric : str (optional, default 'euclidean'). which metric to use when computing neighborhood distances. Defaults to 'euclidean'. Accepted metrics include: -'sqeuclidean' -'euclidean' -'l1' -'lp' - requires setting the parameter p - equivalent to minkowski distance -'cosine' -'angular' -'negdotprod' -'levenshtein' -'hamming' -'jaccard' -'jansen-shan' n_jobs : int (optional, default 1). number of threads to be used in computation. Defaults to 1. The algorithm is highly scalable to multi-threading. M : int (optional, default 10). defines the maximum number of neighbors in the zero and above-zero layers during HSNW (Hierarchical Navigable Small World Graph). However, the actual default maximum number of neighbors for the zero layer is 2*M. A reasonable range for this parameter is 5-100. For more information on HSNW, please check https://arxiv.org/abs/1603.09320. HSNW is implemented in python via NMSlib. Please check more about NMSlib at https://github.com/nmslib/nmslib. efC : int (optional, default 20). A 'hnsw' parameter. Increasing this value improves the quality of a constructed graph and leads to higher accuracy of search. However this also leads to longer indexing times. A reasonable range for this parameter is 10-500. efS : int (optional, default 100). A 'hnsw' parameter. Similarly to efC, increasing this value improves recall at the expense of longer retrieval time. A reasonable range for this parameter is 10-500. t : 'inf' or float or int (optional, default='inf') The decay parameter of heat kernel. The weights are calculated as !!! follow W_{ij} = exp(-(||x_{i}-x_{j}||^2)/t) For more infomation, read the paper 'Laplacian Eigenmaps for Dimensionality Reduction and Data Representation', Belkin, et. al. include_self : bool (optional, default True). All diagonal elements are 1.0 if this parameter is True. is_sparse : bool (optional, default True). Returns a scipy.sparse.csr_matrix object if this parameter is True. Otherwise, returns numpy.ndarray object. return_adj : bool (optional, default False) Whether to return the adjacency matrix instead. verbose : bool (optional, default False). Whether to report information on the current progress of the algorithm.","title":"Parameters"},{"location":"cknn/#fastlapmap.similarities.cknn_graph--returns","text":"The affinity (or adjacency) matrix as a scipy.sparse.csr_matrix or numpy.ndarray object, depending on is_sparse and on return_adj . Source code in fastlapmap/similarities.py def cknn_graph ( X , n_neighbors = 10 , delta = 1.0 , metric = 'euclidean' , n_jobs = 1 , efC = 20 , efS = 20 , M = 10 , p = 11 / 16 , t = 'inf' , include_self = True , is_sparse = False , return_adj = True , verbose = False ): \"\"\" Continuous k-nearest-neighbors. CkNN is the unique unweighted construction that yields a geometry consistent with the connected components of the underlying manifold in the limit of large data. See the [CkNN manuscript](http://dx.doi.org/10.3934/fods.2019001) for details. ---------- Parameters ---------- `X` : input data. May be a numpy.ndarray, a pandas.DataFrame or a scipy.sparse.csr_matrix.numpy `n_neighbors` : int (optional, default 5) Number of neighbors to estimate the density around the point. It appeared as a parameter `k` in the paper. `delta` : float (optional, default 1.0) A parameter to decide the radius for each points. The combination radius increases in proportion to this parameter . `metric` : str (optional, default 'euclidean'). which metric to use when computing neighborhood distances. Defaults to 'euclidean'. Accepted metrics include: -'sqeuclidean' -'euclidean' -'l1' -'lp' - requires setting the parameter `p` - equivalent to minkowski distance -'cosine' -'angular' -'negdotprod' -'levenshtein' -'hamming' -'jaccard' -'jansen-shan' `n_jobs` : int (optional, default 1). number of threads to be used in computation. Defaults to 1. The algorithm is highly scalable to multi-threading. `M` : int (optional, default 10). defines the maximum number of neighbors in the zero and above-zero layers during HSNW (Hierarchical Navigable Small World Graph). However, the actual default maximum number of neighbors for the zero layer is 2*M. A reasonable range for this parameter is 5-100. For more information on HSNW, please check https://arxiv.org/abs/1603.09320. HSNW is implemented in python via NMSlib. Please check more about NMSlib at https://github.com/nmslib/nmslib. `efC` : int (optional, default 20). A 'hnsw' parameter. Increasing this value improves the quality of a constructed graph and leads to higher accuracy of search. However this also leads to longer indexing times. A reasonable range for this parameter is 10-500. `efS` : int (optional, default 100). A 'hnsw' parameter. Similarly to efC, increasing this value improves recall at the expense of longer retrieval time. A reasonable range for this parameter is 10-500. `t` : 'inf' or float or int (optional, default='inf') The decay parameter of heat kernel. The weights are calculated as follow: W_{ij} = exp(-(||x_{i}-x_{j}||^2)/t) For more infomation, read the paper 'Laplacian Eigenmaps for Dimensionality Reduction and Data Representation', Belkin, et. al. `include_self` : bool (optional, default True). All diagonal elements are 1.0 if this parameter is True. `is_sparse` : bool (optional, default True). Returns a scipy.sparse.csr_matrix object if this parameter is True. Otherwise, returns numpy.ndarray object. `return_adj` : bool (optional, default False) Whether to return the adjacency matrix instead. `verbose` : bool (optional, default False). Whether to report information on the current progress of the algorithm. ---------- Returns ---------- The affinity (or adjacency) matrix as a scipy.sparse.csr_matrix or numpy.ndarray object, depending on `is_sparse` and on `return_adj`. \"\"\" n_samples = X . shape [ 0 ] if n_neighbors < 1 or n_neighbors > n_samples - 1 : raise ValueError ( \"`n_neighbors` must be \" \"in the range 1 to number of samples\" ) if len ( X . shape ) != 2 : raise ValueError ( \"`X` must be 2D matrix\" ) if n_samples < 2 : raise ValueError ( \"At least 2 data points are required\" ) if metric == 'precomputed' : if X . shape [ 0 ] != X . shape [ 1 ]: raise ValueError ( \"`X` must be square matrix\" ) dmatrix = X else : knn = NMSlibTransformer ( n_neighbors = n_neighbors , metric = metric , p = p , n_jobs = n_jobs , M = M , efC = efC , efS = efS , verbose = verbose ) . fit_transform ( X ) dmatrix = knn . toarray () darray_n_nbrs = np . partition ( dmatrix , n_neighbors )[:, [ n_neighbors ]] # prevent approximately null results (div by 0) div_matrix = np . sqrt ( darray_n_nbrs . dot ( darray_n_nbrs . T )) + 1e-12 ratio_matrix = dmatrix / div_matrix diag_ptr = np . arange ( n_samples ) if isinstance ( delta , ( int , float )): ValueError ( \"Invalid argument type. \" \"Type of `delta` must be float or int\" ) A = csr_matrix ( ratio_matrix < delta ) if include_self : A [ diag_ptr , diag_ptr ] = True else : A [ diag_ptr , diag_ptr ] = False if return_adj : return A else : if t == 'inf' : K = A . astype ( np . float ) else : mask = A . nonzero () weights = np . exp ( - np . power ( dmatrix [ mask ], 2 ) / t ) dmatrix [:] = 0. dmatrix [ mask ] = weights K = csr_matrix ( dmatrix ) if not is_sparse : K = K . toarray () return K","title":"Returns"},{"location":"diffusion/","text":"fastlapmap . similarities . diffusion_harmonics ( X , n_neighbors = 10 , metric = 'euclidean' , n_jobs = 1 , efC = 20 , efS = 20 , M = 10 , p = 0.6875 , verbose = False ) Computes the diffusion potential between samples using an anisotropic diffusion method (renormalized by median k-nearest-neighbor). Parameters X : input data. May be a numpy.ndarray, a pandas.DataFrame or a scipy.sparse.csr_matrix.numpy n_neighbors : int (optional, default 10). How many neighbors to use for computations. metric : str (optional, default 'euclidean'). which metric to use when computing neighborhood distances. Defaults to 'euclidean'. Accepted metrics include: -'sqeuclidean' -'euclidean' -'l1' -'lp' - requires setting the parameter p - equivalent to minkowski distance -'cosine' -'angular' -'negdotprod' -'levenshtein' -'hamming' -'jaccard' -'jansen-shan' p : int or float (optional, default 11/16 ) P for the Lp metric, when metric='lp' . Can be fractional. The default 11/16 approximates an astroid norm with some computational efficiency (2^n bases are less painstakinly slow to compute). See https://en.wikipedia.org/wiki/Lp_space for some context. n_jobs : int (optional, default 1). number of threads to be used in computation. Defaults to 1. The algorithm is highly scalable to multi-threading. M : int (optional, default 10). defines the maximum number of neighbors in the zero and above-zero layers during HSNW (Hierarchical Navigable Small World Graph). However, the actual default maximum number of neighbors for the zero layer is 2*M. A reasonable range for this parameter is 5-100. For more information on HSNW, please check https://arxiv.org/abs/1603.09320. HSNW is implemented in python via NMSlib. Please check more about NMSlib at https://github.com/nmslib/nmslib. efC : int (optional, default 20). A 'hnsw' parameter. Increasing this value improves the quality of a constructed graph and leads to higher accuracy of search. However this also leads to longer indexing times. A reasonable range for this parameter is 10-500. efS : int (optional, default 100). A 'hnsw' parameter. Similarly to efC, increasing this value improves recall at the expense of longer retrieval time. A reasonable range for this parameter is 10-500. verbose : bool (optional, default False). Whether to report information on the current progress of the algorithm. Returns W : an affinity matrix encoding diffusion potential between samples. Source code in fastlapmap/similarities.py def diffusion_harmonics ( X , n_neighbors = 10 , metric = 'euclidean' , n_jobs = 1 , efC = 20 , efS = 20 , M = 10 , p = 11 / 16 , verbose = False ): \"\"\" Computes the [diffusion potential](https://doi.org/10.1073/pnas.0500334102) between samples using an anisotropic diffusion method (renormalized by median k-nearest-neighbor). ---------- Parameters ---------- `X` : input data. May be a numpy.ndarray, a pandas.DataFrame or a scipy.sparse.csr_matrix.numpy `n_neighbors` : int (optional, default 10). How many neighbors to use for computations. `metric` : str (optional, default 'euclidean'). which metric to use when computing neighborhood distances. Defaults to 'euclidean'. Accepted metrics include: -'sqeuclidean' -'euclidean' -'l1' -'lp' - requires setting the parameter `p` - equivalent to minkowski distance -'cosine' -'angular' -'negdotprod' -'levenshtein' -'hamming' -'jaccard' -'jansen-shan' `p` : int or float (optional, default 11/16 ) P for the Lp metric, when ``metric='lp'``. Can be fractional. The default 11/16 approximates an astroid norm with some computational efficiency (2^n bases are less painstakinly slow to compute). See https://en.wikipedia.org/wiki/Lp_space for some context. `n_jobs` : int (optional, default 1). number of threads to be used in computation. Defaults to 1. The algorithm is highly scalable to multi-threading. `M` : int (optional, default 10). defines the maximum number of neighbors in the zero and above-zero layers during HSNW (Hierarchical Navigable Small World Graph). However, the actual default maximum number of neighbors for the zero layer is 2*M. A reasonable range for this parameter is 5-100. For more information on HSNW, please check https://arxiv.org/abs/1603.09320. HSNW is implemented in python via NMSlib. Please check more about NMSlib at https://github.com/nmslib/nmslib. `efC` : int (optional, default 20). A 'hnsw' parameter. Increasing this value improves the quality of a constructed graph and leads to higher accuracy of search. However this also leads to longer indexing times. A reasonable range for this parameter is 10-500. `efS` : int (optional, default 100). A 'hnsw' parameter. Similarly to efC, increasing this value improves recall at the expense of longer retrieval time. A reasonable range for this parameter is 10-500. `verbose` : bool (optional, default False). Whether to report information on the current progress of the algorithm. ---------- Returns ------- `W` : an affinity matrix encoding diffusion potential between samples. \"\"\" N = np . shape ( X )[ 0 ] knn = NMSlibTransformer ( n_neighbors = n_neighbors , metric = metric , p = p , n_jobs = n_jobs , M = M , efC = efC , efS = efS , verbose = verbose ) . fit_transform ( X ) median_k = np . floor ( n_neighbors / 2 ) . astype ( np . int ) adap_sd = np . zeros ( np . shape ( X )[ 0 ]) for i in np . arange ( len ( adap_sd )): adap_sd [ i ] = np . sort ( knn . data [ knn . indptr [ i ]: knn . indptr [ i + 1 ]])[ median_k - 1 ] x , y , dists = find ( knn ) dists = dists / ( adap_sd [ x ] + 1e-10 ) W = csr_matrix (( np . exp ( - dists ), ( x , y )), shape = [ N , N ]) return W","title":"Diffusion harmonics"},{"location":"diffusion/#fastlapmap.similarities.diffusion_harmonics","text":"Computes the diffusion potential between samples using an anisotropic diffusion method (renormalized by median k-nearest-neighbor).","title":"diffusion_harmonics()"},{"location":"diffusion/#fastlapmap.similarities.diffusion_harmonics--parameters","text":"X : input data. May be a numpy.ndarray, a pandas.DataFrame or a scipy.sparse.csr_matrix.numpy n_neighbors : int (optional, default 10). How many neighbors to use for computations. metric : str (optional, default 'euclidean'). which metric to use when computing neighborhood distances. Defaults to 'euclidean'. Accepted metrics include: -'sqeuclidean' -'euclidean' -'l1' -'lp' - requires setting the parameter p - equivalent to minkowski distance -'cosine' -'angular' -'negdotprod' -'levenshtein' -'hamming' -'jaccard' -'jansen-shan' p : int or float (optional, default 11/16 ) P for the Lp metric, when metric='lp' . Can be fractional. The default 11/16 approximates an astroid norm with some computational efficiency (2^n bases are less painstakinly slow to compute). See https://en.wikipedia.org/wiki/Lp_space for some context. n_jobs : int (optional, default 1). number of threads to be used in computation. Defaults to 1. The algorithm is highly scalable to multi-threading. M : int (optional, default 10). defines the maximum number of neighbors in the zero and above-zero layers during HSNW (Hierarchical Navigable Small World Graph). However, the actual default maximum number of neighbors for the zero layer is 2*M. A reasonable range for this parameter is 5-100. For more information on HSNW, please check https://arxiv.org/abs/1603.09320. HSNW is implemented in python via NMSlib. Please check more about NMSlib at https://github.com/nmslib/nmslib. efC : int (optional, default 20). A 'hnsw' parameter. Increasing this value improves the quality of a constructed graph and leads to higher accuracy of search. However this also leads to longer indexing times. A reasonable range for this parameter is 10-500. efS : int (optional, default 100). A 'hnsw' parameter. Similarly to efC, increasing this value improves recall at the expense of longer retrieval time. A reasonable range for this parameter is 10-500. verbose : bool (optional, default False). Whether to report information on the current progress of the algorithm.","title":"Parameters"},{"location":"diffusion/#fastlapmap.similarities.diffusion_harmonics--returns","text":"W : an affinity matrix encoding diffusion potential between samples. Source code in fastlapmap/similarities.py def diffusion_harmonics ( X , n_neighbors = 10 , metric = 'euclidean' , n_jobs = 1 , efC = 20 , efS = 20 , M = 10 , p = 11 / 16 , verbose = False ): \"\"\" Computes the [diffusion potential](https://doi.org/10.1073/pnas.0500334102) between samples using an anisotropic diffusion method (renormalized by median k-nearest-neighbor). ---------- Parameters ---------- `X` : input data. May be a numpy.ndarray, a pandas.DataFrame or a scipy.sparse.csr_matrix.numpy `n_neighbors` : int (optional, default 10). How many neighbors to use for computations. `metric` : str (optional, default 'euclidean'). which metric to use when computing neighborhood distances. Defaults to 'euclidean'. Accepted metrics include: -'sqeuclidean' -'euclidean' -'l1' -'lp' - requires setting the parameter `p` - equivalent to minkowski distance -'cosine' -'angular' -'negdotprod' -'levenshtein' -'hamming' -'jaccard' -'jansen-shan' `p` : int or float (optional, default 11/16 ) P for the Lp metric, when ``metric='lp'``. Can be fractional. The default 11/16 approximates an astroid norm with some computational efficiency (2^n bases are less painstakinly slow to compute). See https://en.wikipedia.org/wiki/Lp_space for some context. `n_jobs` : int (optional, default 1). number of threads to be used in computation. Defaults to 1. The algorithm is highly scalable to multi-threading. `M` : int (optional, default 10). defines the maximum number of neighbors in the zero and above-zero layers during HSNW (Hierarchical Navigable Small World Graph). However, the actual default maximum number of neighbors for the zero layer is 2*M. A reasonable range for this parameter is 5-100. For more information on HSNW, please check https://arxiv.org/abs/1603.09320. HSNW is implemented in python via NMSlib. Please check more about NMSlib at https://github.com/nmslib/nmslib. `efC` : int (optional, default 20). A 'hnsw' parameter. Increasing this value improves the quality of a constructed graph and leads to higher accuracy of search. However this also leads to longer indexing times. A reasonable range for this parameter is 10-500. `efS` : int (optional, default 100). A 'hnsw' parameter. Similarly to efC, increasing this value improves recall at the expense of longer retrieval time. A reasonable range for this parameter is 10-500. `verbose` : bool (optional, default False). Whether to report information on the current progress of the algorithm. ---------- Returns ------- `W` : an affinity matrix encoding diffusion potential between samples. \"\"\" N = np . shape ( X )[ 0 ] knn = NMSlibTransformer ( n_neighbors = n_neighbors , metric = metric , p = p , n_jobs = n_jobs , M = M , efC = efC , efS = efS , verbose = verbose ) . fit_transform ( X ) median_k = np . floor ( n_neighbors / 2 ) . astype ( np . int ) adap_sd = np . zeros ( np . shape ( X )[ 0 ]) for i in np . arange ( len ( adap_sd )): adap_sd [ i ] = np . sort ( knn . data [ knn . indptr [ i ]: knn . indptr [ i + 1 ]])[ median_k - 1 ] x , y , dists = find ( knn ) dists = dists / ( adap_sd [ x ] + 1e-10 ) W = csr_matrix (( np . exp ( - dists ), ( x , y )), shape = [ N , N ]) return W","title":"Returns"},{"location":"fuzzy/","text":"fastlapmap . similarities . fuzzy_simplicial_set_ann ( X , n_neighbors = 15 , knn_indices = None , knn_dists = None , backend = 'nmslib' , metric = 'cosine' , n_jobs = None , efC = 50 , efS = 50 , M = 15 , set_op_mix_ratio = 1.0 , local_connectivity = 1.0 , apply_set_operations = True , return_dists = False , verbose = False ) Given a set of data X, a neighborhood size, and a measure of distance compute the fuzzy simplicial set (here represented as a fuzzy graph in the form of a sparse matrix) associated to the data. This is done by locally approximating geodesic distance at each point, creating a fuzzy simplicial set for each such point, and then combining all the local fuzzy simplicial sets into a global one via a fuzzy union. This algorithm was first implemented and made popular in UMAP . Parameters X : array of shape (n_samples, n_features). The data to be modelled as a fuzzy simplicial set. n_neighbors : int. The number of neighbors to use to approximate geodesic distance. Larger numbers induce more global estimates of the manifold that can miss finer detail, while smaller values will focus on fine manifold structure to the detriment of the larger picture. backend : str (optional, default 'nmslib'). Which backend to use to compute nearest-neighbors. Options for fast, approximate nearest-neighbors are 'nmslib' (default) and 'hnswlib'. For exact nearest-neighbors, use 'sklearn'. metric : str (optional, default 'cosine'). Distance metric for building an approximate kNN graph. Defaults to 'cosine'. Users are encouraged to explore different metrics, such as 'euclidean' and 'inner_product'. The 'hamming' and 'jaccard' distances are also available for string vectors. Accepted metrics include NMSLib , HNSWlib * and sklearn metrics. Some examples are: -'sqeuclidean' (*, **) -'euclidean' (*, **) -'l1' (*) -'lp' - requires setting the parameter ``p`` (*) - similar to Minkowski -'cosine' (*, **) -'inner_product' (**) -'angular' (*) -'negdotprod' (*) -'levenshtein' (*) -'hamming' (*) -'jaccard' (*) -'jansen-shan' (*). n_jobs : int (optional, default 1). number of threads to be used in computation. Defaults to 1. The algorithm is highly scalable to multi-threading. M : int (optional, default 30). defines the maximum number of neighbors in the zero and above-zero layers during HSNW (Hierarchical Navigable Small World Graph). However, the actual default maximum number of neighbors for the zero layer is 2*M. A reasonable range for this parameter is 5-100. For more information on HSNW, please check https://arxiv.org/abs/1603.09320. HSNW is implemented in python via NMSlib. Please check more about NMSlib at https://github.com/nmslib/nmslib. efC : int (optional, default 100). A 'hnsw' parameter. Increasing this value improves the quality of a constructed graph and leads to higher accuracy of search. However this also leads to longer indexing times. A reasonable range for this parameter is 50-2000. efS : int (optional, default 100). A 'hnsw' parameter. Similarly to efC, increasing this value improves recall at the expense of longer retrieval time. A reasonable range for this parameter is 50-2000. knn_indices : array of shape (n_samples, n_neighbors) (optional). If the k-nearest neighbors of each point has already been calculated you can pass them in here to save computation time. This should be an array with the indices of the k-nearest neighbors as a row for each data point. knn_dists : array of shape (n_samples, n_neighbors) (optional). If the k-nearest neighbors of each point has already been calculated you can pass them in here to save computation time. This should be an array with the distances of the k-nearest neighbors as a row for each data point. set_op_mix_ratio : float (optional, default 1.0). Interpolate between (fuzzy) union and intersection as the set operation used to combine local fuzzy simplicial sets to obtain a global fuzzy simplicial sets. Both fuzzy set operations use the product t-norm. The value of this parameter should be between 0.0 and 1.0; a value of 1.0 will use a pure fuzzy union, while 0.0 will use a pure fuzzy intersection. local_connectivity : int (optional, default 1) The local connectivity required -- i.e. the number of nearest neighbors that should be assumed to be connected at a local level. The higher this value the more connected the manifold becomes locally. In practice this should be not more than the local intrinsic dimension of the manifold. verbose : bool (optional, default False) Whether to report information on the current progress of the algorithm. return_dists : bool or None (optional, default none) Whether to return the pairwise distance associated with each edge. Returns fuzzy_simplicial_set : coo_matrix A fuzzy simplicial set represented as a sparse matrix. The (i, j) entry of the matrix represents the membership strength of the 1-simplex between the ith and jth sample points. Source code in fastlapmap/similarities.py def fuzzy_simplicial_set_ann ( X , n_neighbors = 15 , knn_indices = None , knn_dists = None , backend = 'nmslib' , metric = 'cosine' , n_jobs = None , efC = 50 , efS = 50 , M = 15 , set_op_mix_ratio = 1.0 , local_connectivity = 1.0 , apply_set_operations = True , return_dists = False , verbose = False ): \"\"\" Given a set of data X, a neighborhood size, and a measure of distance compute the fuzzy simplicial set (here represented as a fuzzy graph in the form of a sparse matrix) associated to the data. This is done by locally approximating geodesic distance at each point, creating a fuzzy simplicial set for each such point, and then combining all the local fuzzy simplicial sets into a global one via a fuzzy union. This algorithm was first implemented and made popular in [UMAP](https://arxiv.org/abs/1802.03426). ---------- Parameters ---------- `X` : array of shape (n_samples, n_features). The data to be modelled as a fuzzy simplicial set. `n_neighbors` : int. The number of neighbors to use to approximate geodesic distance. Larger numbers induce more global estimates of the manifold that can miss finer detail, while smaller values will focus on fine manifold structure to the detriment of the larger picture. `backend` : str (optional, default 'nmslib'). Which backend to use to compute nearest-neighbors. Options for fast, approximate nearest-neighbors are 'nmslib' (default) and 'hnswlib'. For exact nearest-neighbors, use 'sklearn'. `metric` : str (optional, default 'cosine'). Distance metric for building an approximate kNN graph. Defaults to 'cosine'. Users are encouraged to explore different metrics, such as 'euclidean' and 'inner_product'. The 'hamming' and 'jaccard' distances are also available for string vectors. Accepted metrics include NMSLib*, HNSWlib** and sklearn metrics. Some examples are: -'sqeuclidean' (*, **) -'euclidean' (*, **) -'l1' (*) -'lp' - requires setting the parameter ``p`` (*) - similar to Minkowski -'cosine' (*, **) -'inner_product' (**) -'angular' (*) -'negdotprod' (*) -'levenshtein' (*) -'hamming' (*) -'jaccard' (*) -'jansen-shan' (*). `n_jobs` : int (optional, default 1). number of threads to be used in computation. Defaults to 1. The algorithm is highly scalable to multi-threading. `M` : int (optional, default 30). defines the maximum number of neighbors in the zero and above-zero layers during HSNW (Hierarchical Navigable Small World Graph). However, the actual default maximum number of neighbors for the zero layer is 2*M. A reasonable range for this parameter is 5-100. For more information on HSNW, please check https://arxiv.org/abs/1603.09320. HSNW is implemented in python via NMSlib. Please check more about NMSlib at https://github.com/nmslib/nmslib. `efC` : int (optional, default 100). A 'hnsw' parameter. Increasing this value improves the quality of a constructed graph and leads to higher accuracy of search. However this also leads to longer indexing times. A reasonable range for this parameter is 50-2000. `efS` : int (optional, default 100). A 'hnsw' parameter. Similarly to efC, increasing this value improves recall at the expense of longer retrieval time. A reasonable range for this parameter is 50-2000. `knn_indices` : array of shape (n_samples, n_neighbors) (optional). If the k-nearest neighbors of each point has already been calculated you can pass them in here to save computation time. This should be an array with the indices of the k-nearest neighbors as a row for each data point. `knn_dists` : array of shape (n_samples, n_neighbors) (optional). If the k-nearest neighbors of each point has already been calculated you can pass them in here to save computation time. This should be an array with the distances of the k-nearest neighbors as a row for each data point. `set_op_mix_ratio` : float (optional, default 1.0). Interpolate between (fuzzy) union and intersection as the set operation used to combine local fuzzy simplicial sets to obtain a global fuzzy simplicial sets. Both fuzzy set operations use the product t-norm. The value of this parameter should be between 0.0 and 1.0; a value of 1.0 will use a pure fuzzy union, while 0.0 will use a pure fuzzy intersection. `local_connectivity` : int (optional, default 1) The local connectivity required -- i.e. the number of nearest neighbors that should be assumed to be connected at a local level. The higher this value the more connected the manifold becomes locally. In practice this should be not more than the local intrinsic dimension of the manifold. `verbose` : bool (optional, default False) Whether to report information on the current progress of the algorithm. `return_dists` : bool or None (optional, default none) Whether to return the pairwise distance associated with each edge. Returns ------- fuzzy_simplicial_set : coo_matrix A fuzzy simplicial set represented as a sparse matrix. The (i, j) entry of the matrix represents the membership strength of the 1-simplex between the ith and jth sample points. \"\"\" if knn_indices is None or knn_dists is None : if verbose : print ( 'Running fast approximate nearest neighbors with NMSLIB using HNSW...' ) if metric not in [ 'sqeuclidean' , 'euclidean' , 'l1' , 'cosine' , 'angular' , 'negdotprod' , 'levenshtein' , 'hamming' , 'jaccard' , 'jansen-shan' ]: print ( 'Please input a metric compatible with NMSLIB when use_nmslib is set to True' ) knn_indices , knn_dists = approximate_n_neighbors ( X , n_neighbors = n_neighbors , metric = metric , backend = backend , n_jobs = n_jobs , efC = efC , efS = efS , M = M , verbose = verbose ) knn_dists = knn_dists . astype ( np . float32 ) knn_dists = knn_dists sigmas , rhos = smooth_knn_dist ( knn_dists , float ( n_neighbors ), local_connectivity = float ( local_connectivity ), ) rows , cols , vals = compute_membership_strengths ( knn_indices , knn_dists , sigmas , rhos ) result = coo_matrix ( ( vals , ( rows , cols )), shape = ( X . shape [ 0 ], X . shape [ 0 ]) ) result . eliminate_zeros () if apply_set_operations : transpose = result . transpose () prod_matrix = result . multiply ( transpose ) result = ( set_op_mix_ratio * ( result + transpose - prod_matrix ) + ( 1.0 - set_op_mix_ratio ) * prod_matrix ) result . eliminate_zeros () if return_dists : return result , sigmas , rhos , knn_dists else : return result , sigmas , rhos","title":"Fuzzy simplicial sets"},{"location":"fuzzy/#fastlapmap.similarities.fuzzy_simplicial_set_ann","text":"Given a set of data X, a neighborhood size, and a measure of distance compute the fuzzy simplicial set (here represented as a fuzzy graph in the form of a sparse matrix) associated to the data. This is done by locally approximating geodesic distance at each point, creating a fuzzy simplicial set for each such point, and then combining all the local fuzzy simplicial sets into a global one via a fuzzy union. This algorithm was first implemented and made popular in UMAP .","title":"fuzzy_simplicial_set_ann()"},{"location":"fuzzy/#fastlapmap.similarities.fuzzy_simplicial_set_ann--parameters","text":"X : array of shape (n_samples, n_features). The data to be modelled as a fuzzy simplicial set. n_neighbors : int. The number of neighbors to use to approximate geodesic distance. Larger numbers induce more global estimates of the manifold that can miss finer detail, while smaller values will focus on fine manifold structure to the detriment of the larger picture. backend : str (optional, default 'nmslib'). Which backend to use to compute nearest-neighbors. Options for fast, approximate nearest-neighbors are 'nmslib' (default) and 'hnswlib'. For exact nearest-neighbors, use 'sklearn'. metric : str (optional, default 'cosine'). Distance metric for building an approximate kNN graph. Defaults to 'cosine'. Users are encouraged to explore different metrics, such as 'euclidean' and 'inner_product'. The 'hamming' and 'jaccard' distances are also available for string vectors. Accepted metrics include NMSLib , HNSWlib * and sklearn metrics. Some examples are: -'sqeuclidean' (*, **) -'euclidean' (*, **) -'l1' (*) -'lp' - requires setting the parameter ``p`` (*) - similar to Minkowski -'cosine' (*, **) -'inner_product' (**) -'angular' (*) -'negdotprod' (*) -'levenshtein' (*) -'hamming' (*) -'jaccard' (*) -'jansen-shan' (*). n_jobs : int (optional, default 1). number of threads to be used in computation. Defaults to 1. The algorithm is highly scalable to multi-threading. M : int (optional, default 30). defines the maximum number of neighbors in the zero and above-zero layers during HSNW (Hierarchical Navigable Small World Graph). However, the actual default maximum number of neighbors for the zero layer is 2*M. A reasonable range for this parameter is 5-100. For more information on HSNW, please check https://arxiv.org/abs/1603.09320. HSNW is implemented in python via NMSlib. Please check more about NMSlib at https://github.com/nmslib/nmslib. efC : int (optional, default 100). A 'hnsw' parameter. Increasing this value improves the quality of a constructed graph and leads to higher accuracy of search. However this also leads to longer indexing times. A reasonable range for this parameter is 50-2000. efS : int (optional, default 100). A 'hnsw' parameter. Similarly to efC, increasing this value improves recall at the expense of longer retrieval time. A reasonable range for this parameter is 50-2000. knn_indices : array of shape (n_samples, n_neighbors) (optional). If the k-nearest neighbors of each point has already been calculated you can pass them in here to save computation time. This should be an array with the indices of the k-nearest neighbors as a row for each data point. knn_dists : array of shape (n_samples, n_neighbors) (optional). If the k-nearest neighbors of each point has already been calculated you can pass them in here to save computation time. This should be an array with the distances of the k-nearest neighbors as a row for each data point. set_op_mix_ratio : float (optional, default 1.0). Interpolate between (fuzzy) union and intersection as the set operation used to combine local fuzzy simplicial sets to obtain a global fuzzy simplicial sets. Both fuzzy set operations use the product t-norm. The value of this parameter should be between 0.0 and 1.0; a value of 1.0 will use a pure fuzzy union, while 0.0 will use a pure fuzzy intersection. local_connectivity : int (optional, default 1) The local connectivity required -- i.e. the number of nearest neighbors that should be assumed to be connected at a local level. The higher this value the more connected the manifold becomes locally. In practice this should be not more than the local intrinsic dimension of the manifold. verbose : bool (optional, default False) Whether to report information on the current progress of the algorithm. return_dists : bool or None (optional, default none) Whether to return the pairwise distance associated with each edge.","title":"Parameters"},{"location":"fuzzy/#fastlapmap.similarities.fuzzy_simplicial_set_ann--returns","text":"fuzzy_simplicial_set : coo_matrix A fuzzy simplicial set represented as a sparse matrix. The (i, j) entry of the matrix represents the membership strength of the 1-simplex between the ith and jth sample points. Source code in fastlapmap/similarities.py def fuzzy_simplicial_set_ann ( X , n_neighbors = 15 , knn_indices = None , knn_dists = None , backend = 'nmslib' , metric = 'cosine' , n_jobs = None , efC = 50 , efS = 50 , M = 15 , set_op_mix_ratio = 1.0 , local_connectivity = 1.0 , apply_set_operations = True , return_dists = False , verbose = False ): \"\"\" Given a set of data X, a neighborhood size, and a measure of distance compute the fuzzy simplicial set (here represented as a fuzzy graph in the form of a sparse matrix) associated to the data. This is done by locally approximating geodesic distance at each point, creating a fuzzy simplicial set for each such point, and then combining all the local fuzzy simplicial sets into a global one via a fuzzy union. This algorithm was first implemented and made popular in [UMAP](https://arxiv.org/abs/1802.03426). ---------- Parameters ---------- `X` : array of shape (n_samples, n_features). The data to be modelled as a fuzzy simplicial set. `n_neighbors` : int. The number of neighbors to use to approximate geodesic distance. Larger numbers induce more global estimates of the manifold that can miss finer detail, while smaller values will focus on fine manifold structure to the detriment of the larger picture. `backend` : str (optional, default 'nmslib'). Which backend to use to compute nearest-neighbors. Options for fast, approximate nearest-neighbors are 'nmslib' (default) and 'hnswlib'. For exact nearest-neighbors, use 'sklearn'. `metric` : str (optional, default 'cosine'). Distance metric for building an approximate kNN graph. Defaults to 'cosine'. Users are encouraged to explore different metrics, such as 'euclidean' and 'inner_product'. The 'hamming' and 'jaccard' distances are also available for string vectors. Accepted metrics include NMSLib*, HNSWlib** and sklearn metrics. Some examples are: -'sqeuclidean' (*, **) -'euclidean' (*, **) -'l1' (*) -'lp' - requires setting the parameter ``p`` (*) - similar to Minkowski -'cosine' (*, **) -'inner_product' (**) -'angular' (*) -'negdotprod' (*) -'levenshtein' (*) -'hamming' (*) -'jaccard' (*) -'jansen-shan' (*). `n_jobs` : int (optional, default 1). number of threads to be used in computation. Defaults to 1. The algorithm is highly scalable to multi-threading. `M` : int (optional, default 30). defines the maximum number of neighbors in the zero and above-zero layers during HSNW (Hierarchical Navigable Small World Graph). However, the actual default maximum number of neighbors for the zero layer is 2*M. A reasonable range for this parameter is 5-100. For more information on HSNW, please check https://arxiv.org/abs/1603.09320. HSNW is implemented in python via NMSlib. Please check more about NMSlib at https://github.com/nmslib/nmslib. `efC` : int (optional, default 100). A 'hnsw' parameter. Increasing this value improves the quality of a constructed graph and leads to higher accuracy of search. However this also leads to longer indexing times. A reasonable range for this parameter is 50-2000. `efS` : int (optional, default 100). A 'hnsw' parameter. Similarly to efC, increasing this value improves recall at the expense of longer retrieval time. A reasonable range for this parameter is 50-2000. `knn_indices` : array of shape (n_samples, n_neighbors) (optional). If the k-nearest neighbors of each point has already been calculated you can pass them in here to save computation time. This should be an array with the indices of the k-nearest neighbors as a row for each data point. `knn_dists` : array of shape (n_samples, n_neighbors) (optional). If the k-nearest neighbors of each point has already been calculated you can pass them in here to save computation time. This should be an array with the distances of the k-nearest neighbors as a row for each data point. `set_op_mix_ratio` : float (optional, default 1.0). Interpolate between (fuzzy) union and intersection as the set operation used to combine local fuzzy simplicial sets to obtain a global fuzzy simplicial sets. Both fuzzy set operations use the product t-norm. The value of this parameter should be between 0.0 and 1.0; a value of 1.0 will use a pure fuzzy union, while 0.0 will use a pure fuzzy intersection. `local_connectivity` : int (optional, default 1) The local connectivity required -- i.e. the number of nearest neighbors that should be assumed to be connected at a local level. The higher this value the more connected the manifold becomes locally. In practice this should be not more than the local intrinsic dimension of the manifold. `verbose` : bool (optional, default False) Whether to report information on the current progress of the algorithm. `return_dists` : bool or None (optional, default none) Whether to return the pairwise distance associated with each edge. Returns ------- fuzzy_simplicial_set : coo_matrix A fuzzy simplicial set represented as a sparse matrix. The (i, j) entry of the matrix represents the membership strength of the 1-simplex between the ith and jth sample points. \"\"\" if knn_indices is None or knn_dists is None : if verbose : print ( 'Running fast approximate nearest neighbors with NMSLIB using HNSW...' ) if metric not in [ 'sqeuclidean' , 'euclidean' , 'l1' , 'cosine' , 'angular' , 'negdotprod' , 'levenshtein' , 'hamming' , 'jaccard' , 'jansen-shan' ]: print ( 'Please input a metric compatible with NMSLIB when use_nmslib is set to True' ) knn_indices , knn_dists = approximate_n_neighbors ( X , n_neighbors = n_neighbors , metric = metric , backend = backend , n_jobs = n_jobs , efC = efC , efS = efS , M = M , verbose = verbose ) knn_dists = knn_dists . astype ( np . float32 ) knn_dists = knn_dists sigmas , rhos = smooth_knn_dist ( knn_dists , float ( n_neighbors ), local_connectivity = float ( local_connectivity ), ) rows , cols , vals = compute_membership_strengths ( knn_indices , knn_dists , sigmas , rhos ) result = coo_matrix ( ( vals , ( rows , cols )), shape = ( X . shape [ 0 ], X . shape [ 0 ]) ) result . eliminate_zeros () if apply_set_operations : transpose = result . transpose () prod_matrix = result . multiply ( transpose ) result = ( set_op_mix_ratio * ( result + transpose - prod_matrix ) + ( 1.0 - set_op_mix_ratio ) * prod_matrix ) result . eliminate_zeros () if return_dists : return result , sigmas , rhos , knn_dists else : return result , sigmas , rhos","title":"Returns"},{"location":"le/","text":"fastlapmap . spectral . LapEigenmap ( data , n_eigs = 10 , k = 10 , metric = 'euclidean' , efC = 20 , efS = 20 , M = 10 , similarity = 'diffusion' , n_jobs = 1 , norm_laplacian = True , eigen_tol = 0.001 , return_evals = False , p = 0.6875 , verbose = False ) Performs Laplacian Eigenmaps on the input data. Parameters data : numpy.ndarray, pandas.DataFrame or scipy.sparse.csr_matrix Input data. By default will use nmslib for approximate nearest-neighbors, which works both on numpy arrays and sparse matrices (faster and cheaper option). Alternatively, users can provide a precomputed affinity matrix by stating metric='precomputed' . n_eigs : int (optional, default 10). Number of eigenvectors to decompose the graph Laplacian into. k : int (optional, default 10). Number of k-nearest-neighbors to use when computing affinities. metric : str (optional, default 'euclidean'). which metric to use when computing neighborhood distances. Defaults to 'euclidean'. Accepted metrics include: -'sqeuclidean' -'euclidean' -'l1' -'lp' - requires setting the parameter p - equivalent to minkowski distance -'cosine' -'angular' -'negdotprod' -'levenshtein' -'hamming' -'jaccard' -'jansen-shan' M : int (optional, default 10). defines the maximum number of neighbors in the zero and above-zero layers during HSNW (Hierarchical Navigable Small World Graph). However, the actual default maximum number of neighbors for the zero layer is 2*M. A reasonable range for this parameter is 5-100. For more information on HSNW, please check https://arxiv.org/abs/1603.09320. HSNW is implemented in python via NMSlib. Please check more about NMSlib at https://github.com/nmslib/nmslib. efC : int (optional, default 20). A 'hnsw' parameter. Increasing this value improves the quality of a constructed graph and leads to higher accuracy of search. However this also leads to longer indexing times. A reasonable range for this parameter is 10-500. efS : int (optional, default 100). A 'hnsw' parameter. Similarly to efC, increasing this value improves recall at the expense of longer retrieval time. A reasonable range for this parameter is 10-500. n_jobs : int (optional, default 1) How many threads to use in approximate-nearest-neighbors computation. similarity : str (optional, default 'diffusion'). Which algorithm to use for similarity learning. Options are diffusion harmonics ('diffusion') , fuzzy simplicial sets ('fuzzy') and continuous k-nearest-neighbors ('cknn'). norm_laplacian : bool (optional, default True). Whether to renormalize the graph Laplacian. return_evals : bool (optional, default False). Whether to also return the eigenvalues in a tuple of eigenvectors, eigenvalues. Defaults to False. verbose : bool (optional, default False). Whether to report information on the current progress of the algorithm. Returns * If return_evals is True : A tuple of eigenvectors and eigenvalues. * If return_evals is False : An array of ranked eigenvectors. Source code in fastlapmap/spectral.py def LapEigenmap ( data , n_eigs = 10 , k = 10 , metric = 'euclidean' , efC = 20 , efS = 20 , M = 10 , similarity = 'diffusion' , n_jobs = 1 , norm_laplacian = True , eigen_tol = 10e-4 , return_evals = False , p = 11 / 16 , verbose = False ): \"\"\" Performs [Laplacian Eigenmaps](https://www2.imm.dtu.dk/projects/manifold/Papers/Laplacian.pdf) on the input data. ---------- Parameters ---------- `data` : numpy.ndarray, pandas.DataFrame or scipy.sparse.csr_matrix Input data. By default will use nmslib for approximate nearest-neighbors, which works both on numpy arrays and sparse matrices (faster and cheaper option). Alternatively, users can provide a precomputed affinity matrix by stating `metric='precomputed'`. `n_eigs` : int (optional, default 10). Number of eigenvectors to decompose the graph Laplacian into. `k` : int (optional, default 10). Number of k-nearest-neighbors to use when computing affinities. `metric` : str (optional, default 'euclidean'). which metric to use when computing neighborhood distances. Defaults to 'euclidean'. Accepted metrics include: -'sqeuclidean' -'euclidean' -'l1' -'lp' - requires setting the parameter `p` - equivalent to minkowski distance -'cosine' -'angular' -'negdotprod' -'levenshtein' -'hamming' -'jaccard' -'jansen-shan' `M` : int (optional, default 10). defines the maximum number of neighbors in the zero and above-zero layers during HSNW (Hierarchical Navigable Small World Graph). However, the actual default maximum number of neighbors for the zero layer is 2*M. A reasonable range for this parameter is 5-100. For more information on HSNW, please check https://arxiv.org/abs/1603.09320. HSNW is implemented in python via NMSlib. Please check more about NMSlib at https://github.com/nmslib/nmslib. `efC` : int (optional, default 20). A 'hnsw' parameter. Increasing this value improves the quality of a constructed graph and leads to higher accuracy of search. However this also leads to longer indexing times. A reasonable range for this parameter is 10-500. `efS` : int (optional, default 100). A 'hnsw' parameter. Similarly to efC, increasing this value improves recall at the expense of longer retrieval time. A reasonable range for this parameter is 10-500. `n_jobs` : int (optional, default 1) How many threads to use in approximate-nearest-neighbors computation. `similarity` : str (optional, default 'diffusion'). Which algorithm to use for similarity learning. Options are diffusion harmonics ('diffusion') , fuzzy simplicial sets ('fuzzy') and continuous k-nearest-neighbors ('cknn'). `norm_laplacian` : bool (optional, default True). Whether to renormalize the graph Laplacian. `return_evals` : bool (optional, default False). Whether to also return the eigenvalues in a tuple of eigenvectors, eigenvalues. Defaults to False. `verbose` : bool (optional, default False). Whether to report information on the current progress of the algorithm. ---------- Returns ---------- * If return_evals is True : A tuple of eigenvectors and eigenvalues. * If return_evals is False : An array of ranked eigenvectors. \"\"\" N = np . shape ( data )[ 0 ] if isinstance ( data , np . ndarray ): data = csr_matrix ( data ) elif isinstance ( data , pd . DataFrame ): data = data . to_numpy () data = csr_matrix ( data ) else : return print ( 'Data should be a numpy.ndarray,pandas.DataFrame or' 'a scipy.sparse.csr_matrix for obtaining approximate nearest neighbors with \\' nmslib \\' .' ) if metric != 'precomputed' : if similarity == 'diffusion' : W = diffusion_harmonics ( data , n_neighbors = k , metric = metric , n_jobs = n_jobs ) elif similarity == 'fuzzy' : fuzzy_results = fuzzy_simplicial_set_ann ( data , n_neighbors = k , metric = metric , n_jobs = n_jobs ) W = fuzzy_results [ 0 ] elif similarity == 'cknn' : W = cknn_graph ( data , n_neighbors = k , metric = metric , n_jobs = n_jobs , include_self = True , is_sparse = True , return_adj = False ) # Enforce symmetry W = ( W + W . T ) / 2 laplacian , dd = sparse . csgraph . laplacian ( W , normed = norm_laplacian , return_diag = True ) laplacian = _set_diag ( laplacian , 1 , norm_laplacian ) laplacian *= - 1 n_eigs = n_eigs + 1 evals , evecs = sparse . linalg . eigsh ( laplacian , k = n_eigs , which = 'LM' , sigma = 1.0 , tol = eigen_tol ) evecs = evecs . T [ n_eigs :: - 1 ] if norm_laplacian : # recover u = D^-1/2 x from the eigenvector output x evecs = evecs / dd evecs = evecs [ 1 : n_eigs ] . T if return_evals : return evecs , evals else : return evecs","title":"Laplacian Eigenmaps"},{"location":"le/#fastlapmap.spectral.LapEigenmap","text":"Performs Laplacian Eigenmaps on the input data.","title":"LapEigenmap()"},{"location":"le/#fastlapmap.spectral.LapEigenmap--parameters","text":"data : numpy.ndarray, pandas.DataFrame or scipy.sparse.csr_matrix Input data. By default will use nmslib for approximate nearest-neighbors, which works both on numpy arrays and sparse matrices (faster and cheaper option). Alternatively, users can provide a precomputed affinity matrix by stating metric='precomputed' . n_eigs : int (optional, default 10). Number of eigenvectors to decompose the graph Laplacian into. k : int (optional, default 10). Number of k-nearest-neighbors to use when computing affinities. metric : str (optional, default 'euclidean'). which metric to use when computing neighborhood distances. Defaults to 'euclidean'. Accepted metrics include: -'sqeuclidean' -'euclidean' -'l1' -'lp' - requires setting the parameter p - equivalent to minkowski distance -'cosine' -'angular' -'negdotprod' -'levenshtein' -'hamming' -'jaccard' -'jansen-shan' M : int (optional, default 10). defines the maximum number of neighbors in the zero and above-zero layers during HSNW (Hierarchical Navigable Small World Graph). However, the actual default maximum number of neighbors for the zero layer is 2*M. A reasonable range for this parameter is 5-100. For more information on HSNW, please check https://arxiv.org/abs/1603.09320. HSNW is implemented in python via NMSlib. Please check more about NMSlib at https://github.com/nmslib/nmslib. efC : int (optional, default 20). A 'hnsw' parameter. Increasing this value improves the quality of a constructed graph and leads to higher accuracy of search. However this also leads to longer indexing times. A reasonable range for this parameter is 10-500. efS : int (optional, default 100). A 'hnsw' parameter. Similarly to efC, increasing this value improves recall at the expense of longer retrieval time. A reasonable range for this parameter is 10-500. n_jobs : int (optional, default 1) How many threads to use in approximate-nearest-neighbors computation. similarity : str (optional, default 'diffusion'). Which algorithm to use for similarity learning. Options are diffusion harmonics ('diffusion') , fuzzy simplicial sets ('fuzzy') and continuous k-nearest-neighbors ('cknn'). norm_laplacian : bool (optional, default True). Whether to renormalize the graph Laplacian. return_evals : bool (optional, default False). Whether to also return the eigenvalues in a tuple of eigenvectors, eigenvalues. Defaults to False. verbose : bool (optional, default False). Whether to report information on the current progress of the algorithm.","title":"Parameters"},{"location":"le/#fastlapmap.spectral.LapEigenmap--returns","text":"* If return_evals is True : A tuple of eigenvectors and eigenvalues. * If return_evals is False : An array of ranked eigenvectors. Source code in fastlapmap/spectral.py def LapEigenmap ( data , n_eigs = 10 , k = 10 , metric = 'euclidean' , efC = 20 , efS = 20 , M = 10 , similarity = 'diffusion' , n_jobs = 1 , norm_laplacian = True , eigen_tol = 10e-4 , return_evals = False , p = 11 / 16 , verbose = False ): \"\"\" Performs [Laplacian Eigenmaps](https://www2.imm.dtu.dk/projects/manifold/Papers/Laplacian.pdf) on the input data. ---------- Parameters ---------- `data` : numpy.ndarray, pandas.DataFrame or scipy.sparse.csr_matrix Input data. By default will use nmslib for approximate nearest-neighbors, which works both on numpy arrays and sparse matrices (faster and cheaper option). Alternatively, users can provide a precomputed affinity matrix by stating `metric='precomputed'`. `n_eigs` : int (optional, default 10). Number of eigenvectors to decompose the graph Laplacian into. `k` : int (optional, default 10). Number of k-nearest-neighbors to use when computing affinities. `metric` : str (optional, default 'euclidean'). which metric to use when computing neighborhood distances. Defaults to 'euclidean'. Accepted metrics include: -'sqeuclidean' -'euclidean' -'l1' -'lp' - requires setting the parameter `p` - equivalent to minkowski distance -'cosine' -'angular' -'negdotprod' -'levenshtein' -'hamming' -'jaccard' -'jansen-shan' `M` : int (optional, default 10). defines the maximum number of neighbors in the zero and above-zero layers during HSNW (Hierarchical Navigable Small World Graph). However, the actual default maximum number of neighbors for the zero layer is 2*M. A reasonable range for this parameter is 5-100. For more information on HSNW, please check https://arxiv.org/abs/1603.09320. HSNW is implemented in python via NMSlib. Please check more about NMSlib at https://github.com/nmslib/nmslib. `efC` : int (optional, default 20). A 'hnsw' parameter. Increasing this value improves the quality of a constructed graph and leads to higher accuracy of search. However this also leads to longer indexing times. A reasonable range for this parameter is 10-500. `efS` : int (optional, default 100). A 'hnsw' parameter. Similarly to efC, increasing this value improves recall at the expense of longer retrieval time. A reasonable range for this parameter is 10-500. `n_jobs` : int (optional, default 1) How many threads to use in approximate-nearest-neighbors computation. `similarity` : str (optional, default 'diffusion'). Which algorithm to use for similarity learning. Options are diffusion harmonics ('diffusion') , fuzzy simplicial sets ('fuzzy') and continuous k-nearest-neighbors ('cknn'). `norm_laplacian` : bool (optional, default True). Whether to renormalize the graph Laplacian. `return_evals` : bool (optional, default False). Whether to also return the eigenvalues in a tuple of eigenvectors, eigenvalues. Defaults to False. `verbose` : bool (optional, default False). Whether to report information on the current progress of the algorithm. ---------- Returns ---------- * If return_evals is True : A tuple of eigenvectors and eigenvalues. * If return_evals is False : An array of ranked eigenvectors. \"\"\" N = np . shape ( data )[ 0 ] if isinstance ( data , np . ndarray ): data = csr_matrix ( data ) elif isinstance ( data , pd . DataFrame ): data = data . to_numpy () data = csr_matrix ( data ) else : return print ( 'Data should be a numpy.ndarray,pandas.DataFrame or' 'a scipy.sparse.csr_matrix for obtaining approximate nearest neighbors with \\' nmslib \\' .' ) if metric != 'precomputed' : if similarity == 'diffusion' : W = diffusion_harmonics ( data , n_neighbors = k , metric = metric , n_jobs = n_jobs ) elif similarity == 'fuzzy' : fuzzy_results = fuzzy_simplicial_set_ann ( data , n_neighbors = k , metric = metric , n_jobs = n_jobs ) W = fuzzy_results [ 0 ] elif similarity == 'cknn' : W = cknn_graph ( data , n_neighbors = k , metric = metric , n_jobs = n_jobs , include_self = True , is_sparse = True , return_adj = False ) # Enforce symmetry W = ( W + W . T ) / 2 laplacian , dd = sparse . csgraph . laplacian ( W , normed = norm_laplacian , return_diag = True ) laplacian = _set_diag ( laplacian , 1 , norm_laplacian ) laplacian *= - 1 n_eigs = n_eigs + 1 evals , evecs = sparse . linalg . eigsh ( laplacian , k = n_eigs , which = 'LM' , sigma = 1.0 , tol = eigen_tol ) evecs = evecs . T [ n_eigs :: - 1 ] if norm_laplacian : # recover u = D^-1/2 x from the eigenvector output x evecs = evecs / dd evecs = evecs [ 1 : n_eigs ] . T if return_evals : return evecs , evals else : return evecs","title":"Returns"},{"location":"usage/","text":"Usage See the following example with the handwritten digits data . Here, I visually compare results from the scikit-learn Laplacian Eigenmaps implementation to those from my implementation. Note that this implementation contains two similarity-learning algorithms: anisotropic diffusion maps and fuzzy simplicial sets . # Import libraries # Fastlapmap and Sklearn Lap Eigenmap comparison import numpy as np import matplotlib.pyplot as plt from sklearn.manifold import SpectralEmbedding from fastlapmap.spectral import LapEigenmap from sklearn.datasets import load_digits digits = load_digits() data = digits.data from scipy.sparse import csr_matrix N_EIGS=2 N_NEIGHBORS=10 N_JOBS=10 sk_se = SpectralEmbedding(n_components=N_EIGS, n_neighbors=N_NEIGHBORS, n_jobs=N_JOBS).fit_transform(data) flapmap_diff = LapEigenmap(data, n_eigs=2, metric='euclidean', similarity='diffusion', norm_laplacian=True, k=N_NEIGHBORS, n_jobs=N_JOBS) flapmap_fuzzy = LapEigenmap(data, n_eigs=2, metric='euclidean', similarity='fuzzy', norm_laplacian=True, k=N_NEIGHBORS, n_jobs=N_JOBS) fig, (ax1, ax2, ax3) = plt.subplots(1, 3) fig.suptitle('Handwritten digits data:', fontsize=24) ax1.scatter(sk_se[:, 0], sk_se[:, 1], c=digits.target, cmap='Spectral', s=5) ax1.set_title('Sklearn\\'s Laplacian Eigenmaps', fontsize=20) ax2.scatter(flapmap_diff[:, 0], flapmap_diff[:, 1], c=digits.target, cmap='Spectral', s=5) ax2.set_title('Fast Laplacian Eigenmaps with diffusion harmonics', fontsize=20) ax3.scatter(flapmap_fuzzy[:, 0], flapmap_fuzzy[:, 1], c=digits.target, cmap='Spectral', s=5) ax3.set_title('Fast Laplacian Eigenmaps with fuzzy simplicial sets', fontsize=20) plt.show() As we can see, results are nearly identical.","title":"Usage"},{"location":"usage/#usage","text":"See the following example with the handwritten digits data . Here, I visually compare results from the scikit-learn Laplacian Eigenmaps implementation to those from my implementation. Note that this implementation contains two similarity-learning algorithms: anisotropic diffusion maps and fuzzy simplicial sets . # Import libraries # Fastlapmap and Sklearn Lap Eigenmap comparison import numpy as np import matplotlib.pyplot as plt from sklearn.manifold import SpectralEmbedding from fastlapmap.spectral import LapEigenmap from sklearn.datasets import load_digits digits = load_digits() data = digits.data from scipy.sparse import csr_matrix N_EIGS=2 N_NEIGHBORS=10 N_JOBS=10 sk_se = SpectralEmbedding(n_components=N_EIGS, n_neighbors=N_NEIGHBORS, n_jobs=N_JOBS).fit_transform(data) flapmap_diff = LapEigenmap(data, n_eigs=2, metric='euclidean', similarity='diffusion', norm_laplacian=True, k=N_NEIGHBORS, n_jobs=N_JOBS) flapmap_fuzzy = LapEigenmap(data, n_eigs=2, metric='euclidean', similarity='fuzzy', norm_laplacian=True, k=N_NEIGHBORS, n_jobs=N_JOBS) fig, (ax1, ax2, ax3) = plt.subplots(1, 3) fig.suptitle('Handwritten digits data:', fontsize=24) ax1.scatter(sk_se[:, 0], sk_se[:, 1], c=digits.target, cmap='Spectral', s=5) ax1.set_title('Sklearn\\'s Laplacian Eigenmaps', fontsize=20) ax2.scatter(flapmap_diff[:, 0], flapmap_diff[:, 1], c=digits.target, cmap='Spectral', s=5) ax2.set_title('Fast Laplacian Eigenmaps with diffusion harmonics', fontsize=20) ax3.scatter(flapmap_fuzzy[:, 0], flapmap_fuzzy[:, 1], c=digits.target, cmap='Spectral', s=5) ax3.set_title('Fast Laplacian Eigenmaps with fuzzy simplicial sets', fontsize=20) plt.show() As we can see, results are nearly identical.","title":"Usage"}]}